{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsLVWoVTel7HHXZ1Ow8cqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajatava/ML/blob/main/FeatureSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vStB6dJCPCOs"
      },
      "source": [
        "#Different Methods of **feature selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prmW4TNDPmwb"
      },
      "source": [
        "### 1> ChiSqare test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV7C2vd4OUxw"
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# lets say X denotes features and y output or terget\n",
        "chi2_score, chi_2_p_value = chi2(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJdQaewyPt93"
      },
      "source": [
        "### 2> mRMR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ZWJZbrOi7s"
      },
      "source": [
        " import pandas as pd\n",
        "import pymrmr\n",
        "# lets say df denotes a dataframe with training data of features ref :  http://home.penglab.com/proj/mRMR/\n",
        "pymrmr.mRMR(df, 'MIQ', no_of_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9_4FfZEPyQM"
      },
      "source": [
        "### 3> mifs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXwN9FHkOn2K"
      },
      "source": [
        "import pandas as pd\n",
        "import mifs\n",
        "\n",
        "# lets say X and y are dataframes containing features and terget output respectively\n",
        "\n",
        "feature_selector = mifs.MutualInformationFeatureSelector()\n",
        "feature_selector.fit(X, y)\n",
        "# to filter down to selected features\n",
        "X_filtered = feat_selector.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSPkFCOMP3ED"
      },
      "source": [
        "### 4> Feature Selection with regularization(l1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbqzbZDaOrVp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Lets say xtrain and ytrain denotes the training dataset where X is features and y is the terget.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
        "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
        "\n",
        "selected_features = X_train.columns[(sel_.get_support())]\n",
        "removed_features = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
        "\n",
        "X_train_selected = sel_.transform(X_train.fillna(0))\n",
        "X_test_selected = sel_.transform(X_test.fillna(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDWH4ttDP9ST"
      },
      "source": [
        "### 5> Feature Selection- With Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oroVOGMuOuxn"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Lets say xtrain and ytrain denotes the training dataset where X is features and y is the terget.\n",
        "xc = xtrain.corr() # To get the correlaltion matrix\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "#Using Pearson Correlation\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(xc, annot=True, cmap=plt.cm.CMRmap_r)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# with the following function we can select highly correlated features\n",
        "# it will remove the first feature that is correlated with anything other feature\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "\n",
        "corr_features = correlation(X_train,  threshold = 0.75)\n",
        "\n",
        "# to drop the highly corelated features\n",
        "X_train.drop(corr_features,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-8waKj5QCgH"
      },
      "source": [
        "### 6> Feature Selection- Dropping constant or zero variance features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iRYHZFYOyDD"
      },
      "source": [
        "import pandas as pd \n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "var_thres=VarianceThreshold(threshold=0)\n",
        "# lets say data is a dataframe containing the features\n",
        "var_thres.fit(data)\n",
        "\n",
        "constant_columns = [column for column in data.columns if column not in data.columns[var_thres.get_support()]]\n",
        "\n",
        "# to drop the constant features\n",
        "data.drop(constant_columns,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}